# Guide d'intÃ©gration LLM - Wordle CSP Solver

## ðŸ“– Vue d'ensemble

Ce guide explique comment le solveur Wordle utilise le **function calling** d'OpenAI pour combiner raisonnement linguistique (LLM) et rÃ©solution par contraintes (CSP).

## ðŸŽ¯ Concept : Function Calling

Le function calling permet au LLM d'appeler des fonctions Python pendant une conversation, combinant ainsi :
- **Raisonnement linguistique** du LLM
- **Calculs prÃ©cis** du solveur CSP
- **Optimisation mathÃ©matique** de la thÃ©orie de l'information

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Utilisateurâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚      LLM     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  CSP Solver  â”‚
â”‚              â”‚ Questionâ”‚   (OpenAI)   â”‚ Functionâ”‚              â”‚
â”‚              â”‚         â”‚              â”‚  Call   â”‚              â”‚
â”‚              â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”‚              â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”‚              â”‚
â”‚              â”‚ RÃ©ponse â”‚              â”‚ RÃ©sultatâ”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ”§ Fonctions exposÃ©es au LLM

### 1. apply_wordle_constraints
Applique les contraintes d'un feedback Wordle.

```python
{
    "name": "apply_wordle_constraints",
    "description": "Apply constraints from a Wordle guess feedback",
    "parameters": {
        "guess": str,      # Le mot essayÃ© (5 lettres)
        "feedback": list   # ["green", "yellow", "gray"] pour chaque lettre
    }
}
```

**Exemple d'utilisation par le LLM** :
```
User: "J'ai essayÃ© AROSE et j'ai obtenu gris-gris-jaune-vert-vert"

LLM pense: Je dois appeler apply_wordle_constraints
LLM appelle: apply_wordle_constraints(
    guess="arose",
    feedback=["gray", "gray", "yellow", "green", "green"]
)
RÃ©sultat: {"words_remaining": 47, "success": true}

LLM rÃ©pond: "D'accord ! Avec ce feedback, il reste 47 mots possibles.
Le 'O' est dans le mot mais pas en position 2, et les lettres S et E
sont correctes aux positions 3 et 4. Je suggÃ¨re d'essayer HOUSE."
```

### 2. get_possible_words
RÃ©cupÃ¨re la liste des mots encore possibles.

```python
{
    "name": "get_possible_words",
    "description": "Get list of all words that satisfy current constraints",
    "parameters": {
        "limit": int  # Nombre max de mots Ã  retourner (dÃ©faut: 20)
    }
}
```

**Exemple** :
```
LLM appelle: get_possible_words(limit=10)
RÃ©sultat: ["house", "horse", "mouse", "louse", ...]

LLM rÃ©pond: "Les 10 mots les plus probables sont : house, horse,
mouse... Remarquez qu'ils partagent tous les lettres O, S, E."
```

### 3. suggest_best_guess
SuggÃ¨re le meilleur prochain mot selon une stratÃ©gie.

```python
{
    "name": "suggest_best_guess",
    "description": "Get the optimal next guess",
    "parameters": {
        "strategy": str  # "max_info", "minimax", ou "random"
    }
}
```

**Exemple** :
```
LLM appelle: suggest_best_guess(strategy="max_info")
RÃ©sultat: {"guess": "house", "entropy": 2.43}

LLM rÃ©pond: "Je recommande HOUSE. Ce mot maximise le gain d'information
attendu (entropie de 2.43 bits) et devrait Ã©liminer le plus de candidats."
```

### 4. get_solver_stats
Obtient les statistiques actuelles du solveur.

```python
{
    "name": "get_solver_stats",
    "description": "Get current statistics about the solving process",
    "parameters": {}
}
```

**Exemple** :
```
LLM appelle: get_solver_stats()
RÃ©sultat: {
    "total_words": 500,
    "possible_words": 12,
    "elimination_rate": 0.976,
    "correct_positions": {3: "s", 4: "e"},
    "present_letters": ["o"],
    "absent_letters": ["a", "r"]
}

LLM rÃ©pond: "Excellent progrÃ¨s ! Vous avez Ã©liminÃ© 97.6% des mots.
Il ne reste que 12 candidats. Vous savez que S et E sont correctement
placÃ©s, et que O est dans le mot."
```

### 5. analyze_word_pattern
Analyse les patterns linguistiques dans les mots restants.

```python
{
    "name": "analyze_word_pattern",
    "description": "Analyze linguistic patterns in remaining words",
    "parameters": {
        "aspect": str  # "letter_frequency", "vowel_positions", etc.
    }
}
```

**Exemple** :
```
LLM appelle: analyze_word_pattern(aspect="letter_frequency")
RÃ©sultat: {
    "most_common": [("h", 8), ("o", 12), ("u", 7)],
    "patterns": ["_ou_e", "_o_se"]
}

LLM rÃ©pond: "En analysant les mots restants, je remarque que O apparaÃ®t
dans tous les mots et que le pattern _OU_E est trÃ¨s frÃ©quent.
Les mots se terminent presque tous par SE."
```

## ðŸ’¡ Cas d'usage complets

### Cas 1 : Assistant de rÃ©solution

```python
from llm_integration import WordleLLMAssistant
from csp_solver import WordleCSPSolver
from dictionary_manager import DictionaryManager

# Setup
dict_mgr = DictionaryManager()
dict_mgr.load_default_english()
solver = WordleCSPSolver(5, dict_mgr.get_words())
llm = WordleLLMAssistant(api_key="your-key")

# DÃ©finir les fonctions disponibles
functions = {
    "apply_wordle_constraints": lambda guess, feedback: {
        "success": solver.add_feedback(guess, feedback),
        "words_remaining": len(solver.get_possible_words())
    },
    "get_possible_words": lambda limit=20: {
        "words": solver.get_possible_words()[:limit],
        "total": len(solver.get_possible_words())
    },
    "suggest_best_guess": lambda strategy="max_info": {
        "guess": solver.get_best_guess(strategy),
        "strategy_used": strategy
    },
    "get_solver_stats": lambda: solver.get_stats(),
    "analyze_word_pattern": lambda aspect: {
        "aspect": aspect,
        "analysis": "Pattern analysis result..."
    }
}

# Conversation
response = llm.chat_with_context(
    "J'ai essayÃ© AROSE et obtenu: A gris, R gris, O jaune, S vert, E vert. Que dois-je faire ?",
    functions
)

print(response)
# Output: "Excellente premiÃ¨re tentative ! Le feedback indique que..."
```

### Cas 2 : Analyse stratÃ©gique

```python
# Demander une analyse approfondie
response = llm.chat_with_context(
    "Analyse la situation actuelle et explique quelle stratÃ©gie utiliser",
    functions
)

# Le LLM va :
# 1. Appeler get_solver_stats() pour voir l'Ã©tat
# 2. Appeler analyze_word_pattern() pour trouver des patterns
# 3. Appeler suggest_best_guess() pour diffÃ©rentes stratÃ©gies
# 4. Comparer et expliquer

print(response)
# Output: "BasÃ© sur les 12 mots restants, voici mon analyse..."
```

### Cas 3 : Apprentissage interactif

```python
# L'utilisateur veut comprendre
response = llm.chat_with_context(
    "Pourquoi suggÃ¨res-tu HOUSE plutÃ´t que MOUSE ?",
    functions
)

# Le LLM peut :
# 1. Calculer l'entropie de chaque mot
# 2. Expliquer la thÃ©orie de l'information
# 3. Montrer les patterns Ã©liminÃ©s

print(response)
# Output: "Excellente question ! HOUSE Ã©limine en moyenne 8.3 mots..."
```

## ðŸŽ“ Avantages de l'approche hybride

### 1. PrÃ©cision mathÃ©matique
Le CSP garantit que tous les mots satisfont les contraintes :
```python
# CSP vÃ©rifie automatiquement TOUTES les contraintes
for word in dictionary:
    if satisfies_all_constraints(word):
        possible_words.add(word)
```

### 2. Raisonnement linguistique
Le LLM comprend le contexte et explique :
```
User: "Je veux minimiser le pire cas"
LLM: "D'accord, j'utilise la stratÃ©gie minimax alors..."
[Appelle suggest_best_guess(strategy="minimax")]
```

### 3. FlexibilitÃ© conversationnelle
```
User: "Et si le mot a deux lettres identiques ?"
LLM: "Bonne question ! Avec le CSP, cela crÃ©e des contraintes
supplÃ©mentaires. Par exemple, si 'E' apparaÃ®t en jaune deux fois..."
```

## ðŸ” Exemples de conversations complÃ¨tes

### Conversation 1 : RÃ©solution guidÃ©e

```
User: Aide-moi Ã  rÃ©soudre Wordle

LLM: Bien sÃ»r ! CommenÃ§ons. Pour la premiÃ¨re tentative, je recommande
AROSE qui maximise la couverture des voyelles.

User: J'ai essayÃ© AROSE: A-gris, R-gris, O-jaune, S-vert, E-vert

LLM: [Appelle apply_wordle_constraints("arose", ["gray", "gray", "yellow", "green", "green"])]
[Appelle get_possible_words(limit=10)]

LLM: Parfait ! Il reste 47 mots possibles. Les plus probables sont:
house, horse, mouse, louse. Je recommande HOUSE car il Ã©liminera
le maximum de mots quoi qu'il arrive.

User: Ok, HOUSE: H-vert, O-vert, U-vert, S-vert, E-vert !

LLM: ðŸŽ‰ FÃ©licitations ! Vous avez trouvÃ© le mot en 2 tentatives !
```

### Conversation 2 : Analyse pÃ©dagogique

```
User: Comment fonctionne ton algorithme ?

LLM: J'utilise trois approches complÃ©mentaires:

1. CSP (Constraint Satisfaction): Chaque feedback Wordle devient une
   contrainte mathÃ©matique. Par exemple, "S vert en position 3" signifie
   position[3] = 'S'.

2. ThÃ©orie de l'information: Je calcule l'entropie H = -Î£ p(i)logâ‚‚(p(i))
   pour chaque mot possible et choisis celui qui maximise le gain d'information.

3. Raisonnement linguistique: J'analyse les patterns (prÃ©fixes, suffixes,
   frÃ©quences) pour affiner les suggestions.

User: Montre-moi un calcul d'entropie

LLM: [Appelle suggest_best_guess avec dÃ©tails]

Pour le mot "HOUSE" avec 47 candidats restants:
- Groupe 1 (H_O_SE): 12 mots â†’ p=0.255 â†’ -pÃ—logâ‚‚(p)=0.513 bits
- Groupe 2 (M_O_SE): 8 mots â†’ p=0.170 â†’ -pÃ—logâ‚‚(p)=0.421 bits
- ...
- Entropie totale: 2.43 bits

C'est le gain d'information attendu !
```

### Conversation 3 : Comparaison de stratÃ©gies

```
User: Quelle est la diffÃ©rence entre max_info et minimax ?

LLM: [Appelle suggest_best_guess("max_info")]
[Appelle suggest_best_guess("minimax")]

Excellente question ! Voici la diffÃ©rence:

**Max Info (Entropie)** suggÃ¨re: HOUSE
- Objectif: Maximiser l'information moyenne
- Ã‰limine en moyenne: 8.3 mots par tentative
- Bon pour: Minimiser le nombre moyen de coups

**Minimax** suggÃ¨re: MOUSE
- Objectif: Minimiser le pire cas
- Dans le pire cas: 12 mots restent
- Bon pour: Garantir un nombre maximum de coups

Pour Wordle (6 coups max), je recommande max_info !
```

## ðŸŽ¯ Best Practices

### 1. Toujours valider les entrÃ©es
```python
def apply_wordle_constraints(guess: str, feedback: List[str]) -> Dict:
    # Valider
    if len(guess) != 5:
        return {"error": "Guess must be 5 letters"}
    if len(feedback) != 5:
        return {"error": "Feedback must have 5 elements"}

    # Appliquer
    solver.add_feedback(guess, feedback)
    return {"success": True}
```

### 2. Fournir du contexte dans les rÃ©sultats
```python
def get_solver_stats() -> Dict:
    stats = solver.get_stats()

    # Ajouter du contexte pour le LLM
    stats["interpretation"] = {
        "progress": "excellent" if stats["elimination_rate"] > 0.9 else "good",
        "difficulty": "easy" if stats["possible_words"] < 10 else "medium"
    }

    return stats
```

### 3. GÃ©rer les erreurs gracieusement
```python
try:
    result = solver.get_best_guess()
except Exception as e:
    return {
        "error": str(e),
        "suggestion": "Try resetting the solver"
    }
```

## ðŸ“Š MÃ©triques et monitoring

### Suivre les appels de fonctions
```python
class WordleLLMAssistant:
    def __init__(self):
        self.function_call_stats = {
            "apply_wordle_constraints": 0,
            "get_possible_words": 0,
            "suggest_best_guess": 0,
            # ...
        }

    def track_function_call(self, function_name: str):
        self.function_call_stats[function_name] += 1
```

### Analyser les conversations
```python
def analyze_conversation(conversation_history):
    metrics = {
        "total_turns": len(conversation_history),
        "function_calls": count_function_calls(conversation_history),
        "success_rate": calculate_success_rate(conversation_history)
    }
    return metrics
```

## ðŸš€ Ã‰volutions possibles

### 1. Fonctions avancÃ©es
```python
# Simulation de scÃ©narios
"simulate_guess": lambda guess: {
    "best_case": ...,
    "worst_case": ...,
    "average_case": ...
}

# Comparaison de mots
"compare_words": lambda word1, word2: {
    "entropy_diff": ...,
    "elimination_diff": ...
}
```

### 2. Mode apprentissage
```python
# Le LLM enseigne la stratÃ©gie
"explain_strategy": lambda concept: {
    "explanation": ...,
    "example": ...,
    "visualization": ...
}
```

### 3. Multi-agents
```python
# Plusieurs stratÃ©gies qui dÃ©battent
agents = {
    "entropy_agent": EntropyAgent(),
    "minimax_agent": MinimaxAgent(),
    "frequency_agent": FrequencyAgent()
}

# Le LLM arbitre entre les stratÃ©gies
```

## ðŸ“š Ressources

### Documentation OpenAI
- [Function Calling Guide](https://platform.openai.com/docs/guides/function-calling)
- [Best Practices](https://platform.openai.com/docs/guides/function-calling/best-practices)

### Articles de rÃ©fÃ©rence
- [LLM Tool Use](https://arxiv.org/abs/2307.16789)
- [Toolformer Paper](https://arxiv.org/abs/2302.04761)

### Notre implÃ©mentation
- `llm_integration.py` : Code source
- `game_interface.py` : Utilisation dans l'interface
- `demo.py` : DÃ©monstrations

---

**Conclusion** : L'intÃ©gration LLM via function calling permet de combiner le meilleur des deux mondes : la prÃ©cision algorithmique du CSP et la flexibilitÃ© conversationnelle du LLM.
